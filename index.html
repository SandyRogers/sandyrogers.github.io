<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Sandy Rogers</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="sandy.css" media="all">
        <link href="https://fonts.googleapis.com/css?family=Droid+Sans+Mono" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro&display=swap" rel="stylesheet">
        <link rel="icon" type="image/svg+xml" href="favicon.svg" />
    </head>
    <body>
        <div class='container'>
            <header>
                <h1 id="title">
                <span id="sa">sa</span><span class="dot">.</span><span id="ndy">ndy</span><span id="namespace"> </span><span id="roge">roge</span><span class="dot">.</span><span id="rs">rs</span></h1>
                <p>
                    I write code, mostly in Python and Javascript.
                    I work at <a href="#EBI">EMBL-EBI</a> &mdash; the European Bioinformatics Institute.
                    I previously did a PhD in <a href="#Astronomy">astrophysics research</a> and then worked at <a href="#Saberr">a startup</a>.
                </p>
                <div class="service-links">
                    <div class="service-link">
                        <div class="service-logo medium">M</div><a href="https://medium.com/@sndyrgrs">Medium Stories</a>
                    </div>
                    <div class="service-link">
                        <div class="service-logo linkedin">in</div><a href="https://www.linkedin.com/in/sndyrgrs/">LinkedIn</a>
                    </div>
                    <div class="service-link">
                        <div class="service-logo github">üêôÔ∏è</div><a href="https://github.com/SandyRogers">GitHub</a>
                    </div>
                </div>
                <p>
                    You can find my email on GitHub. Or: it looks like sandyrogers, an @ looks like an a, and I own this domain.
                </p>
                </header>
                
                <section id="ebi-section">
                    
                </section>
                    <a href="#EBI"><h2 id="EBI">EMBL-EBI</h2></a>
                    <p>
                        At <a href="https://www.embl.org">EMBL</a>-<a href="https://ebi.ac.uk">EBI</a>, I‚Äôm a scientific software web developer on <a href="https://www.ebi.ac.uk/metagenomics/">MGnify</a>, the platform for analysis, archival, and discovery of metagenomic data.
                    </p>
                    <p>
                        Our <a href="https://github.com/EBI-Metagenomics/emgapi">codebase</a> is largely open source, and the web service side of our work is mostly <a href="https://python.org">Python</a>/<a href="https://www.djangoproject.com/">Django</a>, javascript/<a href="https://backbonejs.org">backbone.js</a> and <a href="https://reactjs.org">React.js</a>. EBI run their own computing cluster and data centre, so the service‚Äôs underlying data is provided by many tools, languages, and workflows.
                    </p>
                </section>
                <section id='astronomy-section'>
                    <a href="#Astronomy"><h2 id="Astronomy">Astronomy</h2></a>
                    <p>
                        My PhD was at the <a href="http://www.roe.ac.uk">Royal Observatory</a>, <a href="https://ed.ac.uk">Edinburgh</a>. My project mostly used the <a href="http://hubblesite.org/">Hubble Space Telescope</a> to look at very distance galaxies. They are far enough away that we look back into the early Universe when we see them (within the first billion years of its 13 billion year history).
                    </p>
                    <p>
                        We looked for the earliest, faintest galaxies we could find (a few hundred of them at redshift 5 to 9). By carefully measuring their colours and comparing them to computer models of stars and galaxies, we worked out the galaxies‚Äô stellar populations &mdash; the types of stars they contained. The tricky parts were working with very faint galaxies in very noisy image data, measuring colours without bias, and figuring out both the distance to the galaxies as well as their properties (they can have similar patterns).
                    </p>
                    <p>
                        My <a href ="http://hdl.handle.net/1842/9948">thesis</a> is available.
                        My papers are <a href="http://adsabs.harvard.edu/cgi-bin/nph-abs_connect?db_key=AST&qform=AST&arxiv_sel=astro-ph&adsobj_query=YES&aut_logic=AND&obj_logic=OR&author=Rogers%2C+Alexander%0D%0AMcLure%2C+Ross&object=&">on ADS</a>.
                    </p>
                    <p>
                        The most important results of my thesis are in this paper:
                    </p>
                    <blockquote>
                        Rogers, A. B., et al. ‚ÄúThe colour distribution of galaxies at redshift five.‚Äù Monthly Notices of the Royal Astronomical Society 440.4 (2014): 3714-3725.
                        <br/>
                        <a href="http://adsabs.harvard.edu/abs/2014MNRAS.440.3714R">ADS</a>
                    </blockquote>
                </section>
                <section id='saberr-section'>
                    <a href="#Saberr"><h2 id="Saberr">Saberr</h2></a>
                    <p>
                        I worked on a tech startup, Saberr, for 8 years. They focused on workplace teamwork.
                        I did research and data analysis as well as full-stack web development (and various other things you‚Äôd expect in a startup).
                    </p>
                    <p>
                        My favourite feature to work on was <a href="https://medium.com/@sndyrgrs/highlighting-keywords-in-context-with-dependency-parsing-95c1e6a3f334">Smart Tips</a>: a natural language processing feature that annotates users‚Äô meeting agendas with relevant expert guides to help them.
                    It was interesting because:</p>
                    <ul>
                        <li>We didn‚Äôt have much training data, so had to do as much as possible using pre-trained language models and a small expert dataset.</li>
                        <li>We used dependency-parsing in a way that was shown to users to help them understand what the software was trying to guide them on (and why).</li>
                    </ul>
                    <p>
                        I used <a href="https://spacy.io">SpaCy</a> to develop the NLP for that (and <a href="https://blog.saberr.com/7-experiments-in-natural-language-understanding-for-coachbot-308f79843795">several other prototypes</a> that didn't go into production).
                    </p>
                    <p>
                        I spent most of my time using <a href="https://python.org">Python</a>, <a href="https://www.djangoproject.com/">Django</a>, <a href="https://reactjs.org">React.js</a>, <a href="https://jupyter.org/">Jupyter Lab</a>, and <a href="https://aws.amazon.com/">AWS</a>.
                    </p>
                </section>
                <section id='side-projects-section'>
                    <a href="#SideProjects"><h2 id="SideProjects">Side Projects</h2></a>
                    <h3>Pan/tilt/zoom tracking camera</h3>
                    <p>
                        A hardware &amp; software project, to automatically track an object using a consumer point-and-shoot camera.
                        The initial motivation is to film a horse and rider performing <a href="https://en.wikipedia.org/wiki/Dressage">Dressage</a>.
                        Good footage (e.g. for practice review or for virtual compeitions) requires a tight crop even at the other end of an arena.
                    </p>
                    <p>
                        The project uses a <a href="https://www.panasonic.com/uk/consumer/cameras-camcorders/lumix-digital-cameras/superzoom-cameras/dmc-tz70.html">Panasonic TZ70</a>, with reverse-engineered WiFi control and streaming thanks to the camera‚Äôs companion-app capabilities. 
                        A <a href="https://www.raspberrypi.org">Raspberry Pi</a> connects wirelessly to the camera, streams frames over UDP, and controls the pan/tilt via <a href="https://www.monkmakes.com/downloads/instructions_servo_six.pdf">Monkmakes Servosix</a> controller and <a href="https://thepihut.com/products/servo-motor-mg996r-high-torque-metal-gear">TowerPro MG996R</a> servos.
                        Zoom-level and recording status are controlled by issuing WiFi requests to the camera's cgi command server.
                        A 4" touchscreen shows a simple GUI interface and preview.
                        The pan/tilt frame and camera mount are aluminium with steel bearings.
                    </p>
                    <p>
                        The code is all <a href="https://python.org">Python</a>, and uses <a href="https://opencv.org">opencv</a> with a prebuilt caffe deep neural net model to recognise horses and track them in the frame; <a href="https://gpiozero.readthedocs.io/en/stable/">GPIOZero</a> with non-Python timing functions for jitter-less servo control; and <a href="https://lawsie.github.io/guizero/about/">GUIZero</a> for a simple interface.
                        Various tricks and heuristics are needed to preempt the lag and smooth servo and zoom movements.
                    </p>
                    <h3>A training journal app for runners</h3>
                    <p>
                        An app that encourages runners to keep a training journal.
                        It integrates with <a href="https://www.strava.com">Strava</a> and let‚Äôs athletes keep a private diary of their training.
                        The aim is to encourage more honest training notes, and to guide runners to periodise their training to avoid burnout or injury.
                        It‚Äôs built using <a href="https://firebase.google.com">Firebase</a> and <a href="https://reactjs.org">React.js</a>.
                    </p>
                    <h3>An app for conference networking, with emojis</h3>
                    <p>
                        The <a href="http://www.bbmscambridge.com">Building Bridges in Medical Science</a> conference tries to help their attendees make useful connections each year.
                        They have a history of trying out innovative networking tech to help.
                        For the 2017 and 2018 conferences, I made an emoji based meet-and-share-contacts app, called EmojiBadg.es.
                        The app starts with a list of <a href="https://www.eventbrite.co.uk">Eventbrite</a> attendees, and makes printable name badges for them.
                    </p>
                    <p>
                        Each badge has an emoji code on it, like üê®Ô∏èüå≤Ô∏èüìéÔ∏èüçéÔ∏è.
                        People can share their own contact info, and get somebody else's, by keying an emoji code into the web app on their phone.
                    </p>
                </section>
                <section id="more-section">
                    <h2>Mastodon, Medium, Github</h2>
                    <p>
                        Sometimes <a href="https://medium.com/@sndyrgrs">I write things on Medium</a>, like <a href="https://medium.com/@sndyrgrs/formula-one-has-an-incentive-problem-called-qualifying-4d080f93dc4b">this post about making F1 more competitive</a>. In that one, I used a historical F1 database to look at how competitive races need to be for teams to win championship points.
                    </p>
                    <p>
                        Sometimes I post on <a rel="me" href="https://fosstodon.org/@sndyrgrs">Mastodon</a>.
                    </p>
                    <p>
                        Some of my side projects are <a href="https://github.com/sandyrogers">on Github</a>, like <a href="https://github.com/SandyRogers/F1-points-analysis">this repo</a> for that F1 data analysis project.
                    </p>
                </section>
            </div>
        </body>
    </html>
